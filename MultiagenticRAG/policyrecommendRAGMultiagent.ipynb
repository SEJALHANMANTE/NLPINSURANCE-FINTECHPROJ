{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "783735ff",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'nn' from partially initialized module 'torch' (most likely due to a circular import) (d:\\anaconda3\\Lib\\site-packages\\torch\\__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 5\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01magno\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mteam\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Team\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01magno\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodels\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mopenai\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m OpenAIChat\n\u001b[1;32m----> 5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msentence_transformers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SentenceTransformer\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mfaiss\u001b[39;00m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mjson\u001b[39;00m\n",
      "File \u001b[1;32md:\\anaconda3\\Lib\\site-packages\\sentence_transformers\\__init__.py:9\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mimportlib\u001b[39;00m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mos\u001b[39;00m\n\u001b[1;32m----> 9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msentence_transformers\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbackend\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     10\u001b[0m     export_dynamic_quantized_onnx_model,\n\u001b[0;32m     11\u001b[0m     export_optimized_onnx_model,\n\u001b[0;32m     12\u001b[0m     export_static_quantized_openvino_model,\n\u001b[0;32m     13\u001b[0m )\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msentence_transformers\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcross_encoder\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mCrossEncoder\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m CrossEncoder\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msentence_transformers\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdatasets\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ParallelSentencesDataset, SentencesDataset\n",
      "File \u001b[1;32md:\\anaconda3\\Lib\\site-packages\\sentence_transformers\\backend.py:11\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtyping\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m TYPE_CHECKING, Callable, Literal\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mhuggingface_hub\u001b[39;00m\n\u001b[1;32m---> 11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msentence_transformers\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutil\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m disable_datasets_caching, is_datasets_available\n\u001b[0;32m     13\u001b[0m logger \u001b[38;5;241m=\u001b[39m logging\u001b[38;5;241m.\u001b[39mgetLogger(\u001b[38;5;18m__name__\u001b[39m)\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m TYPE_CHECKING:\n",
      "File \u001b[1;32md:\\anaconda3\\Lib\\site-packages\\sentence_transformers\\util.py:17\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mrequests\u001b[39;00m\n\u001b[1;32m---> 17\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mhuggingface_hub\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m hf_hub_download, snapshot_download\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Tensor, device\n",
      "File \u001b[1;32md:\\anaconda3\\Lib\\site-packages\\torch\\__init__.py:2108\u001b[0m\n\u001b[0;32m      0\u001b[0m <Error retrieving source code with stack_data see ipython/ipython#13598>\n",
      "File \u001b[1;32md:\\anaconda3\\Lib\\site-packages\\torch\\functional.py:7\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtyping\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Any, List, Optional, Sequence, Tuple, TYPE_CHECKING, Union\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[1;32m----> 7\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfunctional\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mF\u001b[39;00m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _VF, Tensor\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_C\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _add_docstr\n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name 'nn' from partially initialized module 'torch' (most likely due to a circular import) (d:\\anaconda3\\Lib\\site-packages\\torch\\__init__.py)"
     ]
    }
   ],
   "source": [
    "from agno.agent import Agent\n",
    "from agno.team import Team\n",
    "from agno.models.openai import OpenAIChat\n",
    "\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import faiss\n",
    "import json\n",
    "import httpx\n",
    "import numpy as np\n",
    "\n",
    "# ✅ Load assets\n",
    "model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "index = faiss.read_index(r\"D:\\NLPInsuranceProject\\NLPINSURANCE-FINTECHPROJ\\faiss_policy.index\")\n",
    "with open(r\"D:\\NLPInsuranceProject\\NLPINSURANCE-FINTECHPROJ\\policy_metadata.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    metadata_docs = json.load(f)\n",
    "\n",
    "OPENROUTER_API_KEY = \"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\"\n",
    "MODEL_NAME = \"meta-llama/llama-3-70b-instruct:free\"\n",
    "K = 3\n",
    "\n",
    "# ✅ Policy Recommender Agent Callable\n",
    "class PolicyRecommender:\n",
    "    def __call__(self, query: str) -> dict:\n",
    "        query_vector = model.encode([query], convert_to_numpy=True)\n",
    "        D, I = index.search(query_vector, K)\n",
    "        top_docs = [metadata_docs[i] for i in I[0]]\n",
    "\n",
    "        context = \"\\n\".join([f\"- {doc}\" for doc in top_docs])\n",
    "\n",
    "        prompt = f\"\"\"\n",
    "## 🧾 User Query:\n",
    "> **\"{query}\"**\n",
    "\n",
    "## 📘 Top {K} Matching Policy Descriptions:\n",
    "{context}\n",
    "\n",
    "## 🎯 Task:\n",
    "As an expert assistant, recommend **one** health insurance policy from the list above that best fits the user’s query. Explain your reasoning in 2–4 bullet points using simple language. Keep the response short, clear, and in **Markdown format**.\n",
    "\"\"\"\n",
    "\n",
    "        headers = {\n",
    "            \"Authorization\": f\"Bearer {OPENROUTER_API_KEY}\",\n",
    "            \"Content-Type\": \"application/json\"\n",
    "        }\n",
    "\n",
    "        payload = {\n",
    "            \"model\": MODEL_NAME,\n",
    "            \"messages\": [\n",
    "                {\"role\": \"system\", \"content\": \"You are a helpful assistant trained in Indian health insurance policy recommendations. Return replies in Markdown with emojis.\"},\n",
    "                {\"role\": \"user\", \"content\": prompt}\n",
    "            ],\n",
    "            \"temperature\": 0.4,\n",
    "            \"max_tokens\": 512\n",
    "        }\n",
    "\n",
    "        response = httpx.post(\"https://openrouter.ai/api/v1/chat/completions\", headers=headers, json=payload)\n",
    "        response.raise_for_status()\n",
    "        answer = response.json()[\"choices\"][0][\"message\"][\"content\"]\n",
    "\n",
    "        return {\n",
    "            \"recommendation\": answer,\n",
    "            \"top_docs\": top_docs\n",
    "        }\n",
    "\n",
    "# ✅ Policy Justifier Agent Callable\n",
    "class PolicyJustifier:\n",
    "    def __call__(self, input_data: dict) -> str:\n",
    "        rec = input_data[\"recommendation\"]\n",
    "        justification_prompt = f\"\"\"\n",
    "## ✅ Selected Policy Recommendation:\n",
    "{rec}\n",
    "\n",
    "## 🧠 Task:\n",
    "Based on this, explain why this policy was chosen over the others. \n",
    "Consider differences in premium, OPD cover, cashless network, and brand.\n",
    "Be clear, add 2–3 key comparison points in Markdown bullets.\n",
    "\"\"\"\n",
    "\n",
    "        headers = {\n",
    "            \"Authorization\": f\"Bearer {OPENROUTER_API_KEY}\",\n",
    "            \"Content-Type\": \"application/json\"\n",
    "        }\n",
    "\n",
    "        payload = {\n",
    "            \"model\": MODEL_NAME,\n",
    "            \"messages\": [\n",
    "                {\"role\": \"system\", \"content\": \"You are an insurance policy expert who justifies model decisions.\"},\n",
    "                {\"role\": \"user\", \"content\": justification_prompt}\n",
    "            ],\n",
    "            \"temperature\": 0.3,\n",
    "            \"max_tokens\": 256\n",
    "        }\n",
    "\n",
    "        response = httpx.post(\"https://openrouter.ai/api/v1/chat/completions\", headers=headers, json=payload)\n",
    "        response.raise_for_status()\n",
    "        return response.json()[\"choices\"][0][\"message\"][\"content\"]\n",
    "\n",
    "# ✅ Instantiate Agents (no args in constructor, set via attributes)\n",
    "policy_recommender_agent = Agent()\n",
    "policy_recommender_agent.model = PolicyRecommender()\n",
    "policy_recommender_agent.description = \"Retrieves policies and asks LLM to choose the best one\"\n",
    "policy_recommender_agent.markdown = True\n",
    "\n",
    "justifier_agent = Agent()\n",
    "justifier_agent.model = PolicyJustifier()\n",
    "justifier_agent.description = \"Explains why the selected policy is the best\"\n",
    "justifier_agent.markdown = True\n",
    "\n",
    "# ✅ Define Team\n",
    "recommendation_team = Team()\n",
    "recommendation_team.agents = [policy_recommender_agent, justifier_agent]\n",
    "recommendation_team.description = \"Team that retrieves and justifies the best policy recommendation for user queries\"\n",
    "\n",
    "# ✅ Run the team\n",
    "def run_recommendation(query: str):\n",
    "    print(f\"📝 User Query: {query}\")\n",
    "    result = recommendation_team.run(query)\n",
    "    print(\"\\n🎯 Final Recommendation:\\n\")\n",
    "    print(result)\n",
    "\n",
    "# ✅ Try it\n",
    "if __name__ == \"__main__\":\n",
    "    run_recommendation(\"I want a budget plan that includes OPD and covers pre-existing conditions.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80cef853",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
